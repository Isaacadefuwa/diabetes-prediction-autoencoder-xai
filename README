# Anomaly-Based Diabetes Prediction Using Autoencoder and Explainable AI (XAI)
An unsupervised learning model for early diabetes detection using Autoencoder and SHAP for explainability.

This project presents a deep learning-based anomaly detection model that leverages Autoencoders and SHAP (Shapley Additive Explanations) for interpreting predictions in early diabetes diagnosis.

## ğŸ“Š Dataset
- Diabetes Prediction Dataset ( Sourced From Kaggle)
  
## ğŸ§ª Preprocessing
- One-hot encoding
- MinMax normalization
- Class balancing using SMOTE
- Feature selection and scaling
  
## ğŸ› ï¸ Model & Tools
- Autoencoder (unsupervised)
- Hyperparameter tuning with Hyperopt
- SHAP for explainability
- Tools: Python, pandas, scikit-learn, Keras, SHAP, SMOTE

  ## ğŸ“ˆ Results
- Accuracy: 90.92%
- Precision: 49.56%
- Recall: 88.71%
- F1-score: 63.59%
- ROC-AUC: 90%

The model effectively flagged anomalous data points likely to represent diabetic cases.
SHAP analysis revealed that smoking status, BMI, and glucose level were among the most influential features.

## ğŸ” Key Features
- Interpretable AI using SHAP
- Balanced training with SMOTE
- Tuned model architecture via Hyperopt

## âœ… What I Learned
Applied unsupervised learning in a real-world health scenario
Used SHAP for transparent, explainable AI
Improved confidence in Python model building, tuning, and visualization





